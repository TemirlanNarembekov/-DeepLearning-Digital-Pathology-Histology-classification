# Практическое задание №1 — классификация гистологических изображений

Этот ноутбук реализует полный минимально необходимый пайплайн обучения и тестирования сверточной нейросети для задачи многоклассовой классификации гистологических изображений (9 классов тканей).

## Данные

Используются предоставленные наборы данных в формате `.npz`:

- `train_tiny` — обучающая выборка (используется для обучения демонстрационной модели);
- `test_tiny`, `test_small`, `test` — тестовые выборки разного размера.

Загрузка наборов данных реализована через класс `Dataset`, который автоматически скачивает архив по ссылке из Google Drive по имени набора (`train`, `train_small`, `train_tiny`, `test`, `test_small`, `test_tiny`), распаковывает его и предоставляет доступ к изображениям и меткам.

## Архитектура и обучение модели

Модель `Model` — это сверточная нейросеть на PyTorch:

- 5 сверточных слоёв `Conv2d` с нелинейностями ReLU и пулингом `MaxPool2d`;
- автоматический расчёт размерности плоского признакового вектора через служебный метод `_compute_flatten_dim`;
- полносвязный слой `Linear` на 64 нейрона и выходной слой `Linear` на 9 классов;
- функция потерь: `CrossEntropyLoss`;
- оптимизатор: `Adam`;
- обучение на датасете `train_tiny` c помощью `fit(...)`, где данные подаются через обёртку `HistologyTorchDataset` и `torch.utils.data.DataLoader`.

В процессе обучения выводятся значение функции потерь и точность на обучающей выборке по эпохам, а по завершении веса модели сохраняются на диск.

## Результаты

После обучения на `train_tiny` (10 эпох) были получены следующие результаты:

- Обучающая выборка (`train_tiny`):
  - финальная точность на последней эпохе: **~0.90 (acc ≈ 0.8987)**.

Оценка на тестовых наборах выполнена с использованием класса `Metrics` (accuracy и balanced accuracy):

- 10% тестовой выборки `test`:
  - accuracy = **0.9200**
  - balanced accuracy = **0.9200**
- Полная тестовая выборка `test`:
  - accuracy = **0.8864**
  - balanced accuracy = **0.8864**
- Небольшой тестовый набор `test_tiny`:
  - accuracy = **0.8778**
  - balanced accuracy = **0.8778**
- Средний тестовый набор `test_small`:
  - accuracy = **0.8833**
  - balanced accuracy = **0.8833**

Таким образом, модель демонстрирует сопоставимые значения обычной и сбалансированной точности на разных тестовых подвыборках, что говорит о более-менее равномерном качестве по классам.

## Реализованные пункты

В ноутбуке реализованы и продемонстрированы следующие элементы:

1. **Класс `Dataset`**
   - Автоматическая загрузка наборов данных из Google Drive по имени.
   - Хранение изображений и меток в памяти.
   - Методы:
     - `image(i)` — доступ к отдельному изображению;
     - `images_seq(n=None)` — последовательный перебор изображений (для тестирования);
     - `random_image_with_label()` — случайное изображение с меткой;
     - `random_batch_with_labels(n)` — формирование случайного батча;
     - `image_with_label(i)` — пара (изображение, метка) по индексу.

2. **Обёртка `HistologyTorchDataset` для PyTorch**
   - Наследование от `torch.utils.data.Dataset`;
   - Преобразование `numpy`-изображений в `torch.Tensor` формата `[3, H, W]`;
   - Поддержка `transform` и интеграция с `DataLoader`.

3. **Класс `Metrics`**
   - Реализация метрик:
     - `accuracy` (доля правильных ответов),
     - `accuracy_balanced` (balanced accuracy из `sklearn`);
   - Метод `print_all(...)` для удобного вывода метрик с пометкой набора.

4. **Класс `Model`**
   - Полная архитектура сверточной модели (5 conv-блоков + 2 полносвязных слоя).
   - Метод `fit(...)`:
     - обучение модели на любом PyTorch-совместимом датасете;
     - вывод значения функции потерь и точности по эпохам.
   - Методы инференса:
     - `test_on_image(...)` — предсказание класса для одного изображения (в виде `np.ndarray` или `torch.Tensor`);
     - `test_on_dataset(...)` — получение предсказаний для объекта `Dataset` / PyTorch Dataset с поддержкой параметра `limit` (для частичного тестирования).
   - Методы сохранения/загрузки:
     - `save(path)` — сохранение весов через `torch.save(self.state_dict(), path)`;
     - `load(path=None)` — **автоматическая загрузка весов обученной модели из облачного хранилища (Google Drive)**:
       - если локального файла с весами нет, он скачивается по заранее зашитой публичной ссылке с помощью `gdown`;
       - далее веса подгружаются через `load_state_dict`, модель переводится в режим `eval()`.

5. **Пайплайн обучения и тестирования**
   - Обучение модели на `train_tiny` с последующим сохранением лучших весов в файл `best_v1.3_kaggle`.
   - Загрузка сохранённой модели и тестирование на нескольких наборах:
     - `test_tiny`, `test_small`, полный `test`, а также 10% выборки `test`.
   - Вывод всех метрик в едином формате через `Metrics.print_all(...)`.

6. **Работа с облачными источниками данных**
   - Все наборы данных загружаются по ссылкам из Google Drive внутри класса `Dataset`.
   - Веса финальной модели автоматически скачиваются из Google Drive внутри метода `Model.load()` без необходимости ручного указания пути или монтирования личного Google Drive со стороны проверяющего.

README предназначен как краткое резюме структуры решения и основных достигнутых результатов, а также как чек‑лист реализованных требований практического задания.
